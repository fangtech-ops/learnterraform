# 30-eks1 <!-- omit in toc -->

<!-- The TOC and section numberings are generated by VS Code extension "Markdown All in One" -->
- [1. How to Run Terraform in This Folder](#1-how-to-run-terraform-in-this-folder)
- [2. Accessing Kubernetes API Server (Control Plane)](#2-accessing-kubernetes-api-server-control-plane)
- [3. Network Connectivity (AWS Client VPN)](#3-network-connectivity-aws-client-vpn)

# 1. How to Run Terraform in This Folder

For this folder, `terraform apply` can be done by one of the following ways:
  1. This folder is monitored by Atlantis. Submitting a Git Pull Request will trigger Atlantis.
  2. Or, run `terraform apply` manually from a laptop, as illustrated in the sample session below.

```console
  ## On laptop
  ## Launch the Docker container https://github.com/narvar/foundation-local-env
$ nt

  ## Now we're inside the Docker container.
  ## For brevity, we won't display the expanded command prompt.
  ## We will just display a simple prompt "#" for the commands below.

  ## If haven't done so in the past 12 hours:
# sso

# cd ......  # To this folder.

  ## Switch env.
# devops

# terraform apply

  ## This is a quirk (bug?) of the new version 1.x.x of terraform. 
# terraform apply -refresh-only -auto-approve
```

The above commands only create the initial cluster alone without setting up everything else around it.
However, an EKS cluster needs to fit into the surrounding ecosystem. That requires other commands.
See:
  - https://github.com/narvar/terraform-aws-accounts#32-sequence-of-terraform-execution


# 2. Accessing Kubernetes API Server (Control Plane)

Right after this folder is applied via `terraform apply` (either manually or via Atlantis), the newly created EKS cluster isn't accessible via normal configuration for `kubectl` or AWS Admin Console. A newly created EKS cluster is only accessible by its IAM owner (an IAM user or role). In our case, the owner is the `NarvarTerraformRole`. On a laptop, your `~/.aws/config` or `~./.kube/config` or AWS Admin Console login don't usually assume that role (although, with additional configuration not shown here, it could.)

After this folder is applied, we need to go to `../40-eks1-bootstrap` and `terraform apply` there. After that, the `aws-auth` ConfigMap will be populated with the necessary content so that we will be able to access it via our normal `~/.aws/config` or `~./.kube/config` or AWS Admin Console login. See comments in:

  * `../40-eks1-bootstrap/10-kubeconfig-file.tf`
  * `../40-eks1-bootstrap/30-flux-config-map`


# 3. Network Connectivity (AWS Client VPN)

We are setting the following flag:

```hcl
module "eks" {
  source  = "terraform-aws-modules/eks/aws"

  cluster_endpoint_public_access  = false
  ...
}
```

This terraform module doesn't need to run the equivalent of `kubectl`; therefore, it doesn't access the Kubernetes API Server. So, we don't need to be on the AWS Client VPN when running `terraform apply`.

However, after this EKS cluster is created, we need AWS Client VPN whenever we run `kubectl` from our laptop (as well as any other commands/software that access the Kubernetes control plane, e.g., `flux` CLI, `argocd` CLI, `vcluster` CLI, `k9s`, k8slens etc.)
